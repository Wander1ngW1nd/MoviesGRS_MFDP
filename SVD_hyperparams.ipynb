{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import ndcg_score, average_precision_score\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "from clearml import Task\n",
    "from clearml.automation import UniformParameterRange, UniformIntegerParameterRange\n",
    "from clearml.automation import HyperParameterOptimizer\n",
    "from clearml.automation.optuna import OptimizerOptuna\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'\n",
    "train_data = pd.read_parquet(data_path + 'ratings_train.pq')\n",
    "test_data = pd.read_parquet(data_path + 'ratings_test.pq')\n",
    "groups5 = pd.read_parquet(data_path + 'groups5.pq')\n",
    "groups6 = pd.read_parquet(data_path + 'groups6.pq')\n",
    "groups7 = pd.read_parquet(data_path + 'groups7.pq')\n",
    "\n",
    "for i, group in enumerate([groups5, groups6, groups7]):\n",
    "    test_data = test_data.merge(group, on='userId').rename(columns={'group': f'group{i+5}'})\n",
    "test_data\n",
    "\n",
    "del groups5, groups6, groups7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=1f9bdbe5e891426988539c51376dce9a\n",
      "2023-05-28 00:14:23,103 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML results page: https://app.clear.ml/projects/f3cb8157bfe7443abdc531a44bb15332/experiments/1f9bdbe5e891426988539c51376dce9a/output/log\n"
     ]
    }
   ],
   "source": [
    "task = Task.init(\n",
    "    project_name = 'MoviesGRS_MFDP', \n",
    "    task_name = 'SVDRecommender', \n",
    "    task_type=Task.TaskTypes.optimizer,\n",
    "    tags = ['SVD', 'HyperParameterTuning'],\n",
    "    reuse_last_task_id=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rating = train_data.rating.min()\n",
    "max_rating = train_data.rating.max()\n",
    " \n",
    "reader = Reader(rating_scale=(min_rating, max_rating))\n",
    "surprise_train_dataset = Dataset.load_from_df(train_data[['userId', 'movieId', 'rating']], reader)\n",
    "del train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Monitor: Could not detect iteration reporting, falling back to iterations as seconds-from-start\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "  'n_factors': [75, 100, 125],\n",
    "  'n_epochs': [25, 50, 75]\n",
    "}\n",
    " \n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=2)\n",
    "gs.fit(surprise_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.8173886828255589, 'mae': 0.6184700213543655}\n",
      "{'rmse': {'n_factors': 75, 'n_epochs': 25}, 'mae': {'n_factors': 75, 'n_epochs': 25}}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score)\n",
    "print(gs.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "  'n_factors': [25, 50, 75],\n",
    "  'n_epochs': [10, 15, 25]\n",
    "}\n",
    " \n",
    "gs2 = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=2)\n",
    "gs2.fit(surprise_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.8145793811843798, 'mae': 0.6160393481400541}\n",
      "{'rmse': {'n_factors': 25, 'n_epochs': 25}, 'mae': {'n_factors': 25, 'n_epochs': 25}}\n"
     ]
    }
   ],
   "source": [
    "print(gs2.best_score)\n",
    "print(gs2.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "  'n_factors': [10, 17, 25],\n",
    "  'n_epochs': [25, 30, 35]\n",
    "}\n",
    " \n",
    "gs3 = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=2)\n",
    "gs3.fit(surprise_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.8127499756266663, 'mae': 0.6132689833958272}\n",
      "{'rmse': {'n_factors': 17, 'n_epochs': 35}, 'mae': {'n_factors': 17, 'n_epochs': 35}}\n"
     ]
    }
   ],
   "source": [
    "print(gs3.best_score)\n",
    "print(gs3.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "  'n_factors': [15, 17, 20],\n",
    "  'n_epochs': [35, 40, 45]\n",
    "}\n",
    " \n",
    "gs4 = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=2)\n",
    "gs4.fit(surprise_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.8125109695871677, 'mae': 0.6124017024963415}\n",
      "{'rmse': {'n_factors': 15, 'n_epochs': 35}, 'mae': {'n_factors': 17, 'n_epochs': 40}}\n"
     ]
    }
   ],
   "source": [
    "print(gs4.best_score)\n",
    "print(gs4.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
